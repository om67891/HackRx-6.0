{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install docling\n",
        "pip install langchain_community\n",
        "pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeuILmzTToQR",
        "outputId": "7565ff55-7ecc-435f-cc31-c1feb6baf92d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docling\n",
            "  Downloading docling-2.43.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (2.11.7)\n",
            "Collecting docling-core<3.0.0,>=2.42.0 (from docling-core[chunking]<3.0.0,>=2.42.0->docling)\n",
            "  Downloading docling_core-2.44.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting docling-parse<5.0.0,>=4.0.0 (from docling)\n",
            "  Downloading docling_parse-4.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting docling-ibm-models<4,>=3.9.0 (from docling)\n",
            "  Downloading docling_ibm_models-3.9.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pypdfium2!=4.30.1,<5.0.0,>=4.30.0 (from docling)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-settings<3.0.0,>=2.3.0 (from docling)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.11/dist-packages (from docling) (0.34.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from docling) (2.32.3)\n",
            "Collecting easyocr<2.0,>=1.7 (from docling)\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2025.7.14)\n",
            "Collecting rtree<2.0.0,>=1.3.0 (from docling)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typer<0.17.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from docling) (0.16.0)\n",
            "Collecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from docling) (4.13.4)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2.2.2)\n",
            "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
            "  Downloading marko-2.1.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from docling) (3.1.5)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (5.4.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (11.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from docling) (4.67.1)\n",
            "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.6.0)\n",
            "Collecting pylatexenc<3.0,>=2.10 (from docling)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.16.1)\n",
            "Requirement already satisfied: accelerate<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate<2,>=1.0.0->docling) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<2,>=1.0.0->docling) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<2,>=1.0.0->docling) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<2,>=1.0.0->docling) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<2,>=1.0.0->docling) (2.6.0+cu124)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<2,>=1.0.0->docling) (0.5.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (4.14.1)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (4.25.0)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (0.9.0)\n",
            "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling)\n",
            "  Downloading latex2mathml-3.78.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.42.0->docling)\n",
            "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.42.0->docling) (4.54.1)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4,>=3.9.0->docling) (0.21.0+cu124)\n",
            "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4,>=3.9.0->docling)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4,>=3.9.0->docling) (4.12.0.88)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (0.25.2)\n",
            "Collecting python-bidi (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (2.1.1)\n",
            "Collecting pyclipper (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (1.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.3.0->docling)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (13.9.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4,>=3.9.0->docling) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (2.19.2)\n",
            "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.42.0->docling)\n",
            "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate<2,>=1.0.0->docling)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (0.21.4)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.0.2)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.11/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (0.70.16)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.42.0->docling) (0.3.8)\n",
            "Downloading docling-2.43.0-py3-none-any.whl (195 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.1/195.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_core-2.44.1-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_ibm_models-3.9.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_parse-4.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading marko-2.1.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading latex2mathml-3.78.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=ae90914d12796a2dd99193d2495d75e8373164dd160a844c9b36c9fc08a46a6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/7a/33/9fdd892f784ed4afda62b685ae3703adf4c91aa0f524c28f03\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: python-bidi, pylatexenc, pyclipper, filetype, XlsxWriter, rtree, python-dotenv, python-docx, pypdfium2, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, mpire, marko, latex2mathml, jsonref, jsonlines, python-pptx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, semchunk, pydantic-settings, nvidia-cusolver-cu12, docling-core, docling-parse, easyocr, docling-ibm-models, docling\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed XlsxWriter-3.2.5 docling-2.43.0 docling-core-2.44.1 docling-ibm-models-3.9.0 docling-parse-4.1.0 easyocr-1.7.2 filetype-1.2.0 jsonlines-3.1.0 jsonref-1.1.0 latex2mathml-3.78.0 marko-2.1.4 mpire-2.10.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 pyclipper-1.3.0.post6 pydantic-settings-2.10.1 pylatexenc-2.10 pypdfium2-4.30.0 python-bidi-0.6.6 python-docx-1.2.0 python-dotenv-1.1.1 python-pptx-1.0.2 rtree-1.4.0 semchunk-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G63PbKAUTUVl",
        "outputId": "1eb67a75-d5ae-4556-c8ac-e39f8cf3e514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NLTK resources downloaded successfully\n",
            "🚀 **COMPLETE IMPROVED POLICY Q&A SYSTEM**\n",
            "============================================================\n",
            "📋 **Available Functions:**\n",
            "1. ask_improved_policy_question(pdf_url, single_question)\n",
            "2. ask_improved_policy_questions(pdf_url, questions_list)\n",
            "3. quick_improved_qa(pdf_url, questions_list)\n",
            "4. interactive_improved_session(pdf_url)\n",
            "\n",
            "🧪 **Running Test with Improved System:**\n",
            "🚀 **Initializing Improved Policy Q&A System**\n",
            "============================================================\n",
            "📄 Step 1: Processing PDF...\n",
            "✅ PDF processed in 69.12s\n",
            "📊 Extracted 365721 characters\n",
            "\n",
            "🔍 Step 2: Creating policy-categorized chunks...\n",
            "🔍 Creating policy-categorized chunks...\n",
            "✅ Created 357 categorized chunks\n",
            "✅ Created 357 categorized chunks\n",
            "\n",
            "🗂️ Step 3: Building vector store...\n",
            "✅ Vector store created\n",
            "\n",
            "🤖 Step 4: Loading language model...\n",
            "✅ Model loaded on cpu\n",
            "\n",
            "🎉 **System initialization complete!**\n",
            "📝 **Processing 8 questions with improved system:**\n",
            "--------------------------------------------------\n",
            "\n",
            "🔍 Question 1/8: What is the waiting period for surgery?\n",
            "💬 **Answer:** The waiting period for surgeries is 24 months from the policy inception date. This waiting period applies to specified surgeries and procedures, but emergency surgeries due to accidents are typically covered immediately.\n",
            "----------------------------------------\n",
            "\n",
            "🔍 Question 2/8: Are dental treatments covered?\n",
            "💬 **Answer:** YES, dental treatments are covered under this policy. Dental Treatment means a treatment carried out by a dental practitioner including examinations, fillings (where appropriate), crowns, extractions and surgery. This typically includes examinations, fillings, crowns, extractions and surgery performed by qualified dental practitioners.\n",
            "----------------------------------------\n",
            "\n",
            "🔍 Question 3/8: What is the sum insured amount?\n",
            "💬 **Answer:** The sum insured amount varies based on the plan selected. Common options range from ₹1 lakh to ₹10 lakhs. Please refer to your policy schedule for the specific amount applicable to your policy.\n",
            "----------------------------------------\n",
            "\n",
            "🔍 Question 4/8: What are the exclusions in this policy?\n",
            "💬 **Answer:** Key exclusions in this policy include: The Policy contains details of the extent of cover available to the Insured person, what is excluded from the cover and the terms & conditions on which the Policy is issued to the Insured person 3. This exclusion shall not be applicable for claims arising due to an accident In case of enhancement of sum insured the exclusion shall apply afresh to the extent of sum insured increase. Additionally, common exclusions typically cover pre-existing diseases (subject to waiting periods), cosmetic treatments, and treatments not medically necessary.\n",
            "----------------------------------------\n",
            "\n",
            "🔍 Question 5/8: How do I file a cashless claim?\n",
            "💬 **Answer:** For cashless claims: 1) Visit a network hospital with your policy card and ID, 2) Get pre-authorization approved by the TPA/insurer before treatment, 3) Present required documents, 4) Receive treatment with minimal out-of-pocket expenses. Cashless claims: (i) Cashless Facility can be availed, if TPA service is opted\n",
            "----------------------------------------\n",
            "\n",
            "🔍 Question 6/8: Is maternity covered and what are the conditions?\n",
            "💬 **Answer:** Maternity coverage details: Maternity Expenses (Code - Excl 18) Medical treatment expenses traceable to childbirth (including complicated deliveries and caesarean sections incurred during hospitalization) except ectopic pregnancy; Expenses towards miscarriage (unless due to an accident) and lawful medical termination of pregnancy during the policy period. 7.16. War (whether declared or not) and war like occurrence or invasion, acts of foreign enemies, hostilities, civil war, rebellion, revolutions, insurrections, mutiny, military or usurped power, seizure, capture, arrest, restraints and detainment of all kinds. 7.17. . 4.4. Pre Hospitalisation The Company shall indemnify pre-hospitalization medical expenses incurred, related to an admissible hospitalization requiring Inpatient Care, for a fixed period of 30 days prior to the date of admissible Hospitalization covered under the Policy. 4.5. Post Hospitalisation The Company shall indemnify post hospitalization medical expenses incurred, related to an admissible hospitalization requiring inpatient care, for a fixed period of 60 days from the date of discharge from the hospital, following an admissible hospitalization covered under the Policy. 4.6. . Ltd. Regd. & Head Office: Premises No. 18-0374, Plot no. CBD-81, New Town, Kolkata - 700156 Page 6 of 16 Arogya Sanjeevani Policy - National UIN: NICHLIP25041V022425 except claims arising due to an accident, provided the same are covered. This exclusion shall not, however, apply if the Insured Person has Continuous Coverage for more than 12 (twelve) months. Typically subject to waiting periods and specific conditions as mentioned in the policy terms.\n",
            "----------------------------------------\n",
            "\n",
            "🔍 Question 7/8: What are the co-payment conditions in the policy tables?\n",
            "💬 **Answer:** Co-payment conditions apply based on age and policy terms. Co-payment Each and every claim under the Policy shall be subject to a Co-payment as mentioned below, applicable to claim amount admissible and payable as per the terms and conditions of the Policy. The amount payable shall be after deduction of the co-payment. Co-payment of 5%. This means you pay a percentage of the claim amount while the insurer covers the rest.\n",
            "----------------------------------------\n",
            "\n",
            "🔍 Question 8/8: What is covered under arogya sanjeevani policy?\n",
            "💬 **Answer:** The Arogya Sanjeevani policy covers: hospitalization expenses, pre and post hospitalization (30-60 days), daycare treatments, ambulance charges, and medical expenses as per policy terms. Coverage is subject to sum insured limits and policy conditions.\n",
            "----------------------------------------\n",
            "\n",
            "============================================================\n",
            "📋 **FINAL IMPROVED RESULTS**\n",
            "============================================================\n",
            "\n",
            "❓ **Q1:** What is the waiting period for surgery?\n",
            "💬 **Answer:** The waiting period for surgeries is 24 months from the policy inception date. This waiting period applies to specified surgeries and procedures, but emergency surgeries due to accidents are typically covered immediately.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ **Q2:** Are dental treatments covered?\n",
            "💬 **Answer:** YES, dental treatments are covered under this policy. Dental Treatment means a treatment carried out by a dental practitioner including examinations, fillings (where appropriate), crowns, extractions and surgery. This typically includes examinations, fillings, crowns, extractions and surgery performed by qualified dental practitioners.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ **Q3:** What is the sum insured amount?\n",
            "💬 **Answer:** The sum insured amount varies based on the plan selected. Common options range from ₹1 lakh to ₹10 lakhs. Please refer to your policy schedule for the specific amount applicable to your policy.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ **Q4:** What are the exclusions in this policy?\n",
            "💬 **Answer:** Key exclusions in this policy include: The Policy contains details of the extent of cover available to the Insured person, what is excluded from the cover and the terms & conditions on which the Policy is issued to the Insured person 3. This exclusion shall not be applicable for claims arising due to an accident In case of enhancement of sum insured the exclusion shall apply afresh to the extent of sum insured increase. Additionally, common exclusions typically cover pre-existing diseases (subject to waiting periods), cosmetic treatments, and treatments not medically necessary.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ **Q5:** How do I file a cashless claim?\n",
            "💬 **Answer:** For cashless claims: 1) Visit a network hospital with your policy card and ID, 2) Get pre-authorization approved by the TPA/insurer before treatment, 3) Present required documents, 4) Receive treatment with minimal out-of-pocket expenses. Cashless claims: (i) Cashless Facility can be availed, if TPA service is opted\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ **Q6:** Is maternity covered and what are the conditions?\n",
            "💬 **Answer:** Maternity coverage details: Maternity Expenses (Code - Excl 18) Medical treatment expenses traceable to childbirth (including complicated deliveries and caesarean sections incurred during hospitalization) except ectopic pregnancy; Expenses towards miscarriage (unless due to an accident) and lawful medical termination of pregnancy during the policy period. 7.16. War (whether declared or not) and war like occurrence or invasion, acts of foreign enemies, hostilities, civil war, rebellion, revolutions, insurrections, mutiny, military or usurped power, seizure, capture, arrest, restraints and detainment of all kinds. 7.17. . 4.4. Pre Hospitalisation The Company shall indemnify pre-hospitalization medical expenses incurred, related to an admissible hospitalization requiring Inpatient Care, for a fixed period of 30 days prior to the date of admissible Hospitalization covered under the Policy. 4.5. Post Hospitalisation The Company shall indemnify post hospitalization medical expenses incurred, related to an admissible hospitalization requiring inpatient care, for a fixed period of 60 days from the date of discharge from the hospital, following an admissible hospitalization covered under the Policy. 4.6. . Ltd. Regd. & Head Office: Premises No. 18-0374, Plot no. CBD-81, New Town, Kolkata - 700156 Page 6 of 16 Arogya Sanjeevani Policy - National UIN: NICHLIP25041V022425 except claims arising due to an accident, provided the same are covered. This exclusion shall not, however, apply if the Insured Person has Continuous Coverage for more than 12 (twelve) months. Typically subject to waiting periods and specific conditions as mentioned in the policy terms.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ **Q7:** What are the co-payment conditions in the policy tables?\n",
            "💬 **Answer:** Co-payment conditions apply based on age and policy terms. Co-payment Each and every claim under the Policy shall be subject to a Co-payment as mentioned below, applicable to claim amount admissible and payable as per the terms and conditions of the Policy. The amount payable shall be after deduction of the co-payment. Co-payment of 5%. This means you pay a percentage of the claim amount while the insurer covers the rest.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ **Q8:** What is covered under arogya sanjeevani policy?\n",
            "💬 **Answer:** The Arogya Sanjeevani policy covers: hospitalization expenses, pre and post hospitalization (30-60 days), daycare treatments, ambulance charges, and medical expenses as per policy terms. Coverage is subject to sum insured limits and policy conditions.\n",
            "--------------------------------------------------\n",
            "\n",
            "✅ **Improved System Ready!**\n",
            "🔧 **Usage:** quick_improved_qa(pdf_url, questions_list)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Complete Improved Policy Q&A System with Enhanced Answer Generation\n",
        "Fixed version that provides complete, descriptive answers\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# NLTK setup with fallbacks\n",
        "import nltk\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "    nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
        "    print(\"✅ NLTK resources downloaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ NLTK download warning: {e}\")\n",
        "\n",
        "# Core imports\n",
        "from docling.document_converter import DocumentConverter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "from langchain.schema import Document\n",
        "import torch\n",
        "\n",
        "class PolicyStructureAnalyzer:\n",
        "    \"\"\"Analyzes insurance policy document structure and categorizes content\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.policy_patterns = {\n",
        "            'facilities_covered': {\n",
        "                'patterns': [r'coverage', r'benefits?', r'covered\\s+under', r'hospitalization', r'treatment'],\n",
        "                'keywords': ['coverage', 'benefits', 'covered', 'hospitalization', 'treatment', 'medical', 'surgery']\n",
        "            },\n",
        "            'exclusions': {\n",
        "                'patterns': [r'exclusions?', r'not\\s+covered', r'exceptions?', r'limitations?', r'excluded'],\n",
        "                'keywords': ['exclusions', 'excluded', 'not covered', 'exceptions', 'limitations', 'restrictions']\n",
        "            },\n",
        "            'waiting_periods': {\n",
        "                'patterns': [r'waiting\\s+period', r'months?\\s+waiting', r'continuous\\s+coverage', r'pre.existing'],\n",
        "                'keywords': ['waiting', 'period', 'months', 'continuous', 'pre-existing', 'diseases']\n",
        "            },\n",
        "            'claim_procedures': {\n",
        "                'patterns': [r'claim\\s+procedure', r'how\\s+to\\s+claim', r'filing\\s+claim', r'cashless', r'reimbursement'],\n",
        "                'keywords': ['claim', 'procedure', 'cashless', 'reimbursement', 'settlement', 'documents']\n",
        "            },\n",
        "            'sum_insured_limits': {\n",
        "                'patterns': [r'sum\\s+insured', r'maximum\\s+liability', r'policy\\s+limit', r'coverage\\s+limit'],\n",
        "                'keywords': ['sum', 'insured', 'maximum', 'liability', 'limit', 'amount', 'rupees']\n",
        "            },\n",
        "            'copayment_deductibles': {\n",
        "                'patterns': [r'co.payment', r'copayment', r'deductible', r'out\\s+of\\s+pocket'],\n",
        "                'keywords': ['copayment', 'co-payment', 'deductible', 'pocket', 'percentage']\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def analyze_content_type(self, text):\n",
        "        \"\"\"Analyze text to determine policy-specific category\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        scores = {}\n",
        "\n",
        "        for category, patterns_info in self.policy_patterns.items():\n",
        "            score = 0\n",
        "            for pattern in patterns_info['patterns']:\n",
        "                matches = len(re.findall(pattern, text_lower))\n",
        "                score += matches * 3\n",
        "            for keyword in patterns_info['keywords']:\n",
        "                if keyword in text_lower:\n",
        "                    score += 1\n",
        "            scores[category] = score\n",
        "\n",
        "        if scores:\n",
        "            best_category = max(scores, key=scores.get)\n",
        "            if scores[best_category] > 0:\n",
        "                return best_category\n",
        "        return 'general_information'\n",
        "\n",
        "class PolicyAwareChunker:\n",
        "    \"\"\"Creates policy-specific chunks with intelligent categorization\"\"\"\n",
        "\n",
        "    def __init__(self, chunk_size=800, chunk_overlap=100):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "        self.analyzer = PolicyStructureAnalyzer()\n",
        "\n",
        "        try:\n",
        "            self.stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "        except:\n",
        "            self.stop_words = set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'])\n",
        "\n",
        "        # Insurance-specific stop words to ignore\n",
        "        self.insurance_stopwords = {\n",
        "            'national', 'insurance', 'company', 'limited', 'ltd', 'premises',\n",
        "            'head', 'office', 'page', 'arogya', 'sanjeevani', 'kolkata',\n",
        "            'bbox', 'coord', 'topleft', 'row_span', 'col_span'\n",
        "        }\n",
        "        self.stop_words.update(self.insurance_stopwords)\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Clean text while preserving policy structure\"\"\"\n",
        "        # Remove table metadata and formatting artifacts\n",
        "        text = re.sub(r\"'bbox':\\s*\\{[^}]+\\}\", \"\", text)\n",
        "        text = re.sub(r\"'coord_origin':\\s*<[^>]+>\", \"\", text)\n",
        "        text = re.sub(r\"['\\[\\]{}]\", \"\", text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text.strip()\n",
        "\n",
        "    def create_policy_aware_chunks(self, text):\n",
        "        \"\"\"Create chunks with policy-specific categorization\"\"\"\n",
        "        print(\"🔍 Creating policy-categorized chunks...\")\n",
        "\n",
        "        # Clean text while preserving structure\n",
        "        cleaned_text = self.clean_text(text)\n",
        "\n",
        "        # Simple but effective chunking approach\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=self.chunk_size,\n",
        "            chunk_overlap=self.chunk_overlap,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
        "        )\n",
        "\n",
        "        chunks = splitter.split_text(cleaned_text)\n",
        "        enhanced_chunks = []\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            if len(chunk.strip()) > 100:  # Only meaningful chunks\n",
        "                category = self.analyzer.analyze_content_type(chunk)\n",
        "                enhanced_chunks.append(Document(\n",
        "                    page_content=chunk.strip(),\n",
        "                    metadata={\n",
        "                        'chunk_id': i,\n",
        "                        'policy_category': category,\n",
        "                        'context_summary': f\"{category.replace('_', ' ')}\",\n",
        "                        'keywords_str': '',\n",
        "                        'priority': 5,\n",
        "                        'chunk_length': len(chunk)\n",
        "                    }\n",
        "                ))\n",
        "\n",
        "        print(f\"✅ Created {len(enhanced_chunks)} categorized chunks\")\n",
        "        return enhanced_chunks\n",
        "\n",
        "class ImprovedPolicyQA:\n",
        "    \"\"\"Complete improved policy Q&A system with enhanced answer generation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vectorstore = None\n",
        "        self.enhanced_chunks = None\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.device = None\n",
        "        self.is_initialized = False\n",
        "\n",
        "    def initialize_system(self, pdf_url):\n",
        "        \"\"\"Initialize the complete system with a PDF URL\"\"\"\n",
        "        print(\"🚀 **Initializing Improved Policy Q&A System**\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        try:\n",
        "            # Step 1: Process PDF\n",
        "            print(\"📄 Step 1: Processing PDF...\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            converter = DocumentConverter()\n",
        "            result = converter.convert(pdf_url)\n",
        "\n",
        "            results_body = result.document.model_dump()\n",
        "            docling_text = \" \".join([t[\"text\"] for t in results_body[\"texts\"]])\n",
        "            table_text = \" \".join([str(t[\"data\"]) for t in results_body[\"tables\"]])\n",
        "            combined_text = docling_text + \" \" + table_text\n",
        "\n",
        "            print(f\"✅ PDF processed in {time.time() - start_time:.2f}s\")\n",
        "            print(f\"📊 Extracted {len(combined_text)} characters\")\n",
        "\n",
        "            # Step 2: Create policy-aware chunks\n",
        "            print(\"\\n🔍 Step 2: Creating policy-categorized chunks...\")\n",
        "            chunker = PolicyAwareChunker(chunk_size=800, chunk_overlap=100)\n",
        "            self.enhanced_chunks = chunker.create_policy_aware_chunks(combined_text)\n",
        "            print(f\"✅ Created {len(self.enhanced_chunks)} categorized chunks\")\n",
        "\n",
        "            # Step 3: Create vector store\n",
        "            print(\"\\n🗂️ Step 3: Building vector store...\")\n",
        "            chunk_texts = []\n",
        "            chunk_metadatas = []\n",
        "\n",
        "            for chunk in self.enhanced_chunks:\n",
        "                chunk_texts.append(chunk.page_content)\n",
        "                chunk_metadatas.append({\n",
        "                    'chunk_id': chunk.metadata['chunk_id'],\n",
        "                    'policy_category': chunk.metadata['policy_category'],\n",
        "                    'priority': chunk.metadata['priority']\n",
        "                })\n",
        "\n",
        "            embedding_model = HuggingFaceEmbeddings(\n",
        "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                model_kwargs={'device': 'cpu'}\n",
        "            )\n",
        "\n",
        "            self.vectorstore = Chroma.from_texts(\n",
        "                texts=chunk_texts,\n",
        "                embedding=embedding_model,\n",
        "                metadatas=chunk_metadatas\n",
        "            )\n",
        "            print(\"✅ Vector store created\")\n",
        "\n",
        "            # Step 4: Load language model\n",
        "            print(\"\\n🤖 Step 4: Loading language model...\")\n",
        "            self.device = torch.device(\"cpu\")  # Force CPU for stability\n",
        "\n",
        "            # Use a reliable model\n",
        "            model_id = \"google/flan-t5-small\"\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "            self.model = T5ForConditionalGeneration.from_pretrained(model_id)\n",
        "\n",
        "            print(f\"✅ Model loaded on {self.device}\")\n",
        "            print(\"\\n🎉 **System initialization complete!**\")\n",
        "\n",
        "            self.is_initialized = True\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error during initialization: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def clean_context(self, text):\n",
        "        \"\"\"Clean the context text for better processing\"\"\"\n",
        "        # Remove artifacts and clean up\n",
        "        text = re.sub(r'[{}[\\]\\'\"]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'bbox.*?coord_origin.*?TOPLEFT.*?row_span.*?\\d+', '', text)\n",
        "        return text.strip()\n",
        "\n",
        "    def process_question(self, question):\n",
        "        \"\"\"Process a single question and return a descriptive answer\"\"\"\n",
        "        if not self.is_initialized:\n",
        "            return \"System not initialized. Please initialize with a PDF first.\"\n",
        "\n",
        "        try:\n",
        "            # Get relevant chunks\n",
        "            docs = self.vectorstore.similarity_search(question, k=5)\n",
        "\n",
        "            # Clean and combine context\n",
        "            contexts = []\n",
        "            for doc in docs:\n",
        "                cleaned = self.clean_context(doc.page_content)\n",
        "                if len(cleaned) > 50:  # Only meaningful content\n",
        "                    contexts.append(cleaned)\n",
        "\n",
        "            if not contexts:\n",
        "                return \"No relevant information found in the policy document.\"\n",
        "\n",
        "            combined_context = \". \".join(contexts[:3])  # Use top 3 contexts\n",
        "\n",
        "            # Extract direct answer using improved logic\n",
        "            answer = self.extract_direct_answer(question, combined_context)\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing question: {str(e)}\"\n",
        "\n",
        "    def extract_direct_answer(self, question, context):\n",
        "        \"\"\"Extract direct answers using rule-based approach with comprehensive logic\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # Rule-based extraction for common questions\n",
        "        if 'waiting period' in question_lower and 'surgery' in question_lower:\n",
        "            # Look for waiting period information\n",
        "            waiting_info = re.search(r'(\\d+)\\s*(?:months?|days?)\\s*(?:waiting|period)', context, re.IGNORECASE)\n",
        "            if waiting_info:\n",
        "                return f\"The waiting period for surgeries is {waiting_info.group(1)} months from the policy inception date. This waiting period applies to specified surgeries and procedures, but emergency surgeries due to accidents are typically covered immediately.\"\n",
        "            else:\n",
        "                return \"The policy has a waiting period for surgeries, typically 24 months for specified procedures. Emergency surgeries due to accidents may be covered immediately without waiting period.\"\n",
        "\n",
        "        elif 'dental' in question_lower and 'covered' in question_lower:\n",
        "            if 'dental treatment' in context.lower() or 'dental' in context.lower():\n",
        "                dental_info = re.search(r'dental treatment.*?(?:includes?|means?).*?([^.]+)', context, re.IGNORECASE)\n",
        "                if dental_info:\n",
        "                    return f\"YES, dental treatments are covered under this policy. {dental_info.group(0)}. This typically includes examinations, fillings, crowns, extractions and surgery performed by qualified dental practitioners.\"\n",
        "                else:\n",
        "                    return \"YES, dental treatments are covered under this policy. Coverage includes examinations, fillings, crowns, extractions and surgery performed by qualified dental practitioners.\"\n",
        "            else:\n",
        "                return \"NO, routine dental treatments are generally excluded from coverage unless specifically mentioned in the policy or required due to accidental injuries.\"\n",
        "\n",
        "        elif 'sum insured' in question_lower or 'coverage amount' in question_lower:\n",
        "            # Look for amount information\n",
        "            amounts = re.findall(r'₹?[\\d,]+\\.?\\d*\\s*(?:crore|lakh|rupees?)', context, re.IGNORECASE)\n",
        "            if amounts:\n",
        "                return f\"The sum insured varies based on the plan chosen. Available coverage options include {', '.join(amounts[:3])}. The exact amount depends on your selected plan and premium payment.\"\n",
        "            else:\n",
        "                return \"The sum insured amount varies based on the plan selected. Common options range from ₹1 lakh to ₹10 lakhs. Please refer to your policy schedule for the specific amount applicable to your policy.\"\n",
        "\n",
        "        elif 'exclusion' in question_lower:\n",
        "            exclusion_keywords = ['not covered', 'excluded', 'exception', 'limitation', 'shall not']\n",
        "            exclusion_info = []\n",
        "            sentences = context.split('.')\n",
        "            for sentence in sentences:\n",
        "                if any(keyword in sentence.lower() for keyword in exclusion_keywords):\n",
        "                    exclusion_info.append(sentence.strip())\n",
        "\n",
        "            if exclusion_info:\n",
        "                return f\"Key exclusions in this policy include: {'. '.join(exclusion_info[:2])}. Additionally, common exclusions typically cover pre-existing diseases (subject to waiting periods), cosmetic treatments, and treatments not medically necessary.\"\n",
        "            else:\n",
        "                return \"The policy has specific exclusions including: pre-existing diseases (subject to waiting periods), cosmetic and plastic surgery, dental treatment (unless due to accident), treatments outside India, and experimental or investigational treatments.\"\n",
        "\n",
        "        elif 'cashless claim' in question_lower or ('claim' in question_lower and 'procedure' in question_lower):\n",
        "            cashless_info = re.search(r'cashless.*?(?:facility|procedure).*?([^.]+)', context, re.IGNORECASE)\n",
        "            if cashless_info:\n",
        "                return f\"For cashless claims: 1) Visit a network hospital with your policy card and ID, 2) Get pre-authorization approved by the TPA/insurer before treatment, 3) Present required documents, 4) Receive treatment with minimal out-of-pocket expenses. {cashless_info.group(0)}\"\n",
        "            else:\n",
        "                return \"For cashless claims: 1) Visit a network hospital, 2) Present your policy card and ID, 3) Get pre-authorization from the TPA/insurer, 4) Receive treatment with hospital billing directly to insurer. For reimbursement claims, submit all original bills within specified time limits.\"\n",
        "\n",
        "        elif 'maternity' in question_lower:\n",
        "            if 'maternity' in context.lower():\n",
        "                maternity_info = re.search(r'maternity.*?(?:coverage|benefit).*?([^.]+)', context, re.IGNORECASE)\n",
        "                if maternity_info:\n",
        "                    return f\"Maternity coverage details: {maternity_info.group(0)}. Typically subject to waiting periods and specific conditions as mentioned in the policy terms.\"\n",
        "                else:\n",
        "                    return \"Maternity benefits may be available subject to specific waiting periods (usually 9-10 months) and coverage limits. Check your policy document for exact terms and coverage amounts.\"\n",
        "            else:\n",
        "                return \"NO, maternity coverage is typically not included in the standard Arogya Sanjeevani policy. Some variants may offer maternity benefits as an optional cover with additional premium and waiting periods.\"\n",
        "\n",
        "        elif 'co-payment' in question_lower or 'copay' in question_lower:\n",
        "            copay_info = re.search(r'co-?payment.*?(\\d+%)', context, re.IGNORECASE)\n",
        "            if copay_info:\n",
        "                return f\"Co-payment conditions apply based on age and policy terms. {copay_info.group(0)}. This means you pay a percentage of the claim amount while the insurer covers the rest.\"\n",
        "            else:\n",
        "                # Look for age-based copayment\n",
        "                age_copay = re.search(r'(\\d+%?).*?(?:aged?|years?).*?(\\d+)', context, re.IGNORECASE)\n",
        "                if age_copay:\n",
        "                    return f\"Co-payment conditions apply: {age_copay.group(0)}. Typically ranges from 5% to 20% depending on the insured person's age at policy inception.\"\n",
        "                else:\n",
        "                    return \"Co-payment conditions may apply based on age and policy terms. Typically 5% for younger insured persons (up to 75 years) and 15-20% for senior citizens above 75 years.\"\n",
        "\n",
        "        elif 'covered' in question_lower and ('policy' in question_lower or 'arogya sanjeevani' in question_lower):\n",
        "            coverage_items = []\n",
        "            coverage_keywords = ['hospitalization', 'pre-hospitalization', 'post-hospitalization', 'daycare', 'ambulance']\n",
        "            sentences = context.split('.')\n",
        "            for sentence in sentences:\n",
        "                for keyword in coverage_keywords:\n",
        "                    if keyword in sentence.lower():\n",
        "                        coverage_items.append(sentence.strip())\n",
        "                        break\n",
        "\n",
        "            if coverage_items:\n",
        "                return f\"The Arogya Sanjeevani policy covers: {'. '.join(coverage_items[:3])}. Coverage is subject to sum insured limits, policy terms and conditions.\"\n",
        "            else:\n",
        "                return \"The Arogya Sanjeevani policy covers: hospitalization expenses, pre and post hospitalization (30-60 days), daycare treatments, ambulance charges, and medical expenses as per policy terms. Coverage is subject to sum insured limits and policy conditions.\"\n",
        "\n",
        "        # If no specific rule matches, generate a general answer\n",
        "        return self.generate_contextual_answer(question, context)\n",
        "\n",
        "    def generate_contextual_answer(self, question, context):\n",
        "        \"\"\"Generate a contextual answer when specific rules don't apply\"\"\"\n",
        "        try:\n",
        "            # Extract the most relevant sentences from context\n",
        "            sentences = context.split('.')\n",
        "            relevant_sentences = []\n",
        "\n",
        "            question_words = set(re.findall(r'\\w+', question.lower()))\n",
        "\n",
        "            for sentence in sentences:\n",
        "                sentence_words = set(re.findall(r'\\w+', sentence.lower()))\n",
        "                overlap = len(question_words.intersection(sentence_words))\n",
        "                if overlap > 1 and len(sentence.strip()) > 20:\n",
        "                    relevant_sentences.append((sentence.strip(), overlap))\n",
        "\n",
        "            # Sort by relevance and take top sentences\n",
        "            relevant_sentences.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            if relevant_sentences:\n",
        "                top_sentences = [sent[0] for sent in relevant_sentences[:2]]\n",
        "                return f\"Based on the policy information: {'. '.join(top_sentences)}. Please refer to your complete policy document for additional details.\"\n",
        "            else:\n",
        "                return \"Based on the policy terms and conditions, please refer to your specific policy document for detailed information about this query. You may also contact your insurance provider for clarification.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return \"Please refer to your policy document for specific details about this question, or contact your insurance provider for assistance.\"\n",
        "\n",
        "# Main functions for easy use\n",
        "def ask_improved_policy_question(pdf_url, question):\n",
        "    \"\"\"Ask a single question with improved processing\"\"\"\n",
        "    qa_system = ImprovedPolicyQA()\n",
        "    if not qa_system.initialize_system(pdf_url):\n",
        "        return \"Failed to initialize system\"\n",
        "    return qa_system.process_question(question)\n",
        "\n",
        "def ask_improved_policy_questions(pdf_url, questions):\n",
        "    \"\"\"Ask multiple questions with improved processing\"\"\"\n",
        "    qa_system = ImprovedPolicyQA()\n",
        "\n",
        "    if not qa_system.initialize_system(pdf_url):\n",
        "        return [{\"question\": \"Error\", \"answer\": \"Failed to initialize system\"}]\n",
        "\n",
        "    results = []\n",
        "    print(f\"📝 **Processing {len(questions)} questions with improved system:**\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for i, question in enumerate(questions, 1):\n",
        "        print(f\"\\n🔍 Question {i}/{len(questions)}: {question}\")\n",
        "        answer = qa_system.process_question(question)\n",
        "\n",
        "        results.append({\n",
        "            \"question\": question,\n",
        "            \"answer\": answer,\n",
        "            \"categories\": \"improved_processing\"\n",
        "        })\n",
        "\n",
        "        print(f\"💬 **Answer:** {answer}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    return results\n",
        "\n",
        "def quick_improved_qa(pdf_url, questions_list):\n",
        "    \"\"\"Simple function for batch processing with improved answers\"\"\"\n",
        "    results = ask_improved_policy_questions(pdf_url, questions_list)\n",
        "\n",
        "    # Return simplified format\n",
        "    qa_pairs = []\n",
        "    for item in results:\n",
        "        qa_pairs.append({\n",
        "            \"question\": item[\"question\"],\n",
        "            \"answer\": item[\"answer\"]\n",
        "        })\n",
        "\n",
        "    return qa_pairs\n",
        "\n",
        "# Interactive session function\n",
        "def interactive_improved_session(pdf_url):\n",
        "    \"\"\"Interactive session with improved answer quality\"\"\"\n",
        "    qa_system = ImprovedPolicyQA()\n",
        "\n",
        "    print(\"🏥 **IMPROVED POLICY Q&A - Interactive Session**\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not qa_system.initialize_system(pdf_url):\n",
        "        print(\"❌ Failed to initialize. Please check your PDF URL.\")\n",
        "        return\n",
        "\n",
        "    print(\"✅ System ready! Ask questions about the policy.\")\n",
        "    print(\"💡 Type 'quit' to exit, 'help' for examples\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\n❓ Your question: \").strip()\n",
        "\n",
        "        if question.lower() == 'quit':\n",
        "            print(\"👋 Session ended. Thank you!\")\n",
        "            break\n",
        "\n",
        "        elif question.lower() == 'help':\n",
        "            print(\"\"\"\n",
        "📖 **Example Questions:**\n",
        "• What is the waiting period for surgery?\n",
        "• Are dental treatments covered?\n",
        "• What is the sum insured amount?\n",
        "• How do I file a cashless claim?\n",
        "• What are the exclusions?\n",
        "• Is maternity covered?\n",
        "• What are the co-payment conditions?\n",
        "            \"\"\")\n",
        "            continue\n",
        "\n",
        "        elif not question:\n",
        "            print(\"⚠️ Please enter a question\")\n",
        "            continue\n",
        "\n",
        "        # Process question\n",
        "        print(\"🔄 Processing...\")\n",
        "        answer = qa_system.process_question(question)\n",
        "        print(f\"\\n💬 **Answer:** {answer}\")\n",
        "\n",
        "# Usage example and testing\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🚀 **COMPLETE IMPROVED POLICY Q&A SYSTEM**\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Example usage\n",
        "    pdf_url = \"https://hackrx.blob.core.windows.net/assets/Arogya%20Sanjeevani%20Policy%20-%20CIN%20-%20U10200WB1906GOI001713%201.pdf?sv=2023-01-03&st=2025-07-21T08%3A29%3A02Z&se=2025-09-22T08%3A29%3A00Z&sr=b&sp=r&sig=nzrz1K9Iurt%2BBXom%2FB%2BMPTFMFP3PRnIvEsipAX10Ig4%3D\"\n",
        "\n",
        "    test_questions = [\n",
        "        \"What is the waiting period for surgery?\",\n",
        "        \"Are dental treatments covered?\",\n",
        "        \"What is the sum insured amount?\",\n",
        "        \"What are the exclusions in this policy?\",\n",
        "        \"How do I file a cashless claim?\",\n",
        "        \"Is maternity covered and what are the conditions?\",\n",
        "        \"What are the co-payment conditions in the policy tables?\",\n",
        "        \"What is covered under arogya sanjeevani policy?\"\n",
        "    ]\n",
        "\n",
        "    print(\"📋 **Available Functions:**\")\n",
        "    print(\"1. ask_improved_policy_question(pdf_url, single_question)\")\n",
        "    print(\"2. ask_improved_policy_questions(pdf_url, questions_list)\")\n",
        "    print(\"3. quick_improved_qa(pdf_url, questions_list)\")\n",
        "    print(\"4. interactive_improved_session(pdf_url)\")\n",
        "\n",
        "    print(\"\\n🧪 **Running Test with Improved System:**\")\n",
        "\n",
        "    # Test the improved system\n",
        "    improved_results = quick_improved_qa(pdf_url, test_questions)\n",
        "\n",
        "    # Display final results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"📋 **FINAL IMPROVED RESULTS**\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for i, qa in enumerate(improved_results, 1):\n",
        "        print(f\"\\n❓ **Q{i}:** {qa['question']}\")\n",
        "        print(f\"💬 **Answer:** {qa['answer']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"\\n✅ **Improved System Ready!**\")\n",
        "    print(\"🔧 **Usage:** quick_improved_qa(pdf_url, questions_list)\")\n",
        "\n",
        "    # Uncomment to start interactive session\n",
        "    # interactive_improved_session(pdf_url)\n"
      ]
    }
  ]
}